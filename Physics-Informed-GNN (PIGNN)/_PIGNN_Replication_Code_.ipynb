{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f707655-cd9f-41de-beba-cd42354d6b24",
   "metadata": {},
   "source": [
    "# **Physics-Informed Graph Neural Network (PIGNN)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433caedb-72b8-4be8-a2b3-3d8945b64fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce GTX 1660 Ti is available.\n",
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = '1'\n",
    "\n",
    "import gc\n",
    "import csv\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "    device = \"cuda\"\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    gc.collect()\n",
    "    print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "    print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "    print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")\n",
    "    device = \"cpu\"\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = False  \n",
    "\n",
    "set_seed(seed=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a111d4-8c91-4e0d-a322-9e0ee4899925",
   "metadata": {},
   "source": [
    "## 1. SAGEConv Layer and architecture definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d377d3bd-0484-4b3e-838a-1ec446786555",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGELayer(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implements a single GraphSAGE layer.\n",
    "    \n",
    "    - Applies message passing by aggregating neighbor embeddings.\n",
    "    - Uses different linear transformations for each edge type.\n",
    "    - Combines neighbor embeddings with self embeddings and applies a ReLU activation.\n",
    "    \n",
    "    Args:\n",
    "        in_dim (int): Input feature dimension.\n",
    "        out_dim (int): Output feature dimension.\n",
    "        edge_dim (int): Number of edge types.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_dim: int, out_dim: int, edge_dim: int): \n",
    "        super().__init__()        \n",
    "        self.lin_neighbors = nn.ModuleList([nn.Linear(in_dim, out_dim, bias=True) for _ in range(edge_dim)])\n",
    "        self.lin_self = nn.Linear(in_dim, out_dim, bias=True)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def message_passing(self, x: torch.Tensor, adj_tensor: torch.Tensor):\n",
    "    \n",
    "        \"\"\"\n",
    "        Performs message passing by aggregating neighbor embeddings using adjacency matrices.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Node feature matrix of shape (batch_size, num_nodes, feature_dim).\n",
    "            adj_tensor (torch.Tensor): Adjacency tensor with multiple edge types.\n",
    "        Returns:\n",
    "            torch.Tensor: Aggregated neighbor embeddings.\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size, num_nodes, _ = x.shape\n",
    "        aggregated_neigh_embeds = []\n",
    "    \n",
    "        for i in range(adj_tensor.shape[3]):  \n",
    "            adj_matrix = adj_tensor[:, :, :, i]  \n",
    "            neigh_embeds_i = torch.bmm(adj_matrix, x) \n",
    "            neigh_embeds_i = self.lin_neighbors[i](neigh_embeds_i)\n",
    "            aggregated_neigh_embeds.append(neigh_embeds_i)\n",
    "\n",
    "        neigh_embeds = sum(aggregated_neigh_embeds)  \n",
    "        return neigh_embeds\n",
    "\n",
    "    def forward(self, x: torch.Tensor, adj_tensor: torch.Tensor):\n",
    "       \n",
    "        \"\"\"\n",
    "        Forward pass of the GraphSAGE layer.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Node feature matrix.\n",
    "            adj_tensor (torch.Tensor): Adjacency tensor.   \n",
    "        Returns:\n",
    "            torch.Tensor: Output node representations.\n",
    "        \"\"\"\n",
    "        \n",
    "        neigh_embeds = self.message_passing(x, adj_tensor)\n",
    "        x_self = self.lin_self(x)\n",
    "        out = neigh_embeds + x_self  \n",
    "        return self.act(out)  \n",
    "\n",
    "class GraphSAGEModel(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    GraphSAGE model with multiple layers for node representation learning.\n",
    "    \n",
    "    - Projects input features to a hidden space.\n",
    "    - Applies three GraphSAGE layers with ReLU activation and dropout.\n",
    "    - Outputs final node embeddings.\n",
    "    \n",
    "    Args:\n",
    "        in_features (int): Input feature dimension.\n",
    "        hidden_size (int): Hidden layer size.\n",
    "        out_features (int): Output feature dimension.\n",
    "        dropout (float): Dropout rate.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features: int, hidden_size: int, out_features: int, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_proj = nn.Linear(in_features, hidden_size, bias=True)        \n",
    "        self.conv1 = GraphSAGELayer(in_dim=hidden_size, out_dim=hidden_size, edge_dim=16)\n",
    "        self.conv2 = GraphSAGELayer(in_dim=hidden_size, out_dim=hidden_size, edge_dim=16)\n",
    "        self.conv3 = GraphSAGELayer(in_dim=hidden_size, out_dim=hidden_size, edge_dim=16)\n",
    "        self.act = nn.ReLU()\n",
    "        self.drop = nn.Dropout(p=dropout)        \n",
    "        self.lin_out = nn.Linear(hidden_size, hidden_size, bias=True)  \n",
    "\n",
    "    def forward(self, x: torch.Tensor, adj_tensor: torch.Tensor):\n",
    "        \n",
    "        \"\"\"\n",
    "        Forward pass of the GraphSAGE model.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input node features.\n",
    "            adj_tensor (torch.Tensor): Adjacency tensor.\n",
    "        Returns:\n",
    "            torch.Tensor: Node embeddings.\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        x = self.conv1(x, adj_tensor)  \n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.conv2(x, adj_tensor) \n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin_out(x)  \n",
    "        return x \n",
    "\n",
    "class DNN(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep Neural Network (DNN) for path prediction.\n",
    "    \n",
    "    - Consists of five fully connected layers with ReLU activations.\n",
    "    - Outputs a probability score using a sigmoid activation.\n",
    "    \n",
    "    Args:\n",
    "        in_features (int): Input feature dimension.\n",
    "        hidden_size (int): Hidden layer size.\n",
    "        out_features (int): Output feature dimension.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, hidden_size, out_features):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc5 = nn.Linear(hidden_size, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \n",
    "        \"\"\"\n",
    "        Forward pass of the DNN.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input features.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Output probabilities.\n",
    "        \"\"\"\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = torch.sigmoid(self.fc5(x))  \n",
    "        return x\n",
    "\n",
    "class GraphSAGEWithDNN(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Combines GraphSAGE and DNN for path prediction.\n",
    "    \n",
    "    - First extracts node embeddings using GraphSAGE.\n",
    "    - Then applies DNN to predict paths.\n",
    "    \n",
    "    Args:\n",
    "        in_features (int): Input feature dimension.\n",
    "        hidden_size (int): Hidden layer size.\n",
    "        out_features (int): Output feature dimension.\n",
    "        dropout (float): Dropout rate.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, hidden_size, out_features, dropout=0):\n",
    "        super().__init__()\n",
    "        self.graphsage = GraphSAGEModel(in_features, hidden_size, hidden_size, dropout)\n",
    "        self.dnn = DNN(hidden_size, hidden_size, out_features)\n",
    "\n",
    "    def forward(self, x, adj_tensor):\n",
    "    \n",
    "        \"\"\"\n",
    "        Forward pass of the combined model.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input node features.\n",
    "            adj_tensor (torch.Tensor): Adjacency tensor.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Predicted paths.\n",
    "        \"\"\"\n",
    "        \n",
    "        node_embeddings = self.graphsage(x, adj_tensor)\n",
    "        output = self.dnn(node_embeddings)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68715c64-9788-4e58-a184-214268fc9b33",
   "metadata": {},
   "source": [
    "## 2. Dataloader, Loss Functions, Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275d040-0dec-4490-9b41-cb98512a1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    \n",
    "    \"\"\"\n",
    "    Custom dataset loader for graph data.\n",
    "        - Loads adjacency tensor, node features (X_matrix), and target adjacency matrix (Y_matrix).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir):\n",
    "        self.files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.pt')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.load(self.files[idx])\n",
    "        return data[\"adj_tensor\"], data[\"X_matrix\"], data[\"Y_matrix\"]\n",
    "\n",
    "\"\"\"\n",
    "Initializes dataset and splits it into training and testing sets.\n",
    "Creates data loaders for efficient batch processing during training.\n",
    "\"\"\"\n",
    "\n",
    "data_dir = \"_data_\"\n",
    "dataset = GraphDataset(data_dir)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, \n",
    "                              worker_init_fn=lambda worker_id: np.random.seed(42 + worker_id), \n",
    "                              generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, \n",
    "                             worker_init_fn=lambda worker_id: np.random.seed(42 + worker_id), \n",
    "                             generator=torch.Generator().manual_seed(42))  \n",
    "\n",
    "def degree_loss(B):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the degree loss to enforce a single path structure in the adjacency matrix B.\n",
    "    \n",
    "    Args:\n",
    "        B (torch.Tensor): Adjacency matrix of shape (B, N, N)\n",
    "    Returns:\n",
    "        torch.Tensor: Degree loss value\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size, num_nodes, _ = B.shape\n",
    "    deg_out = B.sum(dim=-1)  \n",
    "    deg_in = B.sum(dim=-2)  \n",
    "    active_nodes = (deg_in > 0) | (deg_out > 0)  \n",
    "    num_start_nodes = (deg_in == 0) & (deg_out > 0)  \n",
    "    P_start = (num_start_nodes.sum(dim=-1) - 1) ** 2  \n",
    "    num_end_nodes = (deg_out == 0) & (deg_in > 0) \n",
    "    P_end = (num_end_nodes.sum(dim=-1) - 1) ** 2  \n",
    "    incorrect_intermediate = ((deg_in != 1) | (deg_out != 1)) & active_nodes \n",
    "    P_intermediate = incorrect_intermediate.sum(dim=-1) - 2 \n",
    "    P_intermediate = torch.clamp(P_intermediate, min=0)      \n",
    "    L_deg = P_start + P_end + P_intermediate\n",
    "    \n",
    "    return L_deg.float().mean()\n",
    "\n",
    "def cycle_loss(B, K=10):\n",
    "    \n",
    "    \"\"\"\n",
    "    Penalizes cycles in the predicted adjacency matrix B by computing matrix powers up to K.\n",
    "\n",
    "    Args:\n",
    "        B (torch.Tensor): Adjacency matrix of shape (B, N, N).\n",
    "        K (int, optional): Maximum power to compute. Defaults to 10.\n",
    "    Returns:\n",
    "        torch.Tensor: Cycle loss value.\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size, num_nodes, _ = B.shape\n",
    "    B = B / (B.sum(dim=-1, keepdim=True) + 1e-6)\n",
    "    cycle_penalty = torch.zeros(batch_size, device=B.device)\n",
    "    B_power = torch.eye(num_nodes, device=B.device).unsqueeze(0).expand(batch_size, -1, -1)\n",
    "\n",
    "    for k in range(1, K + 1):  \n",
    "        B_power = torch.bmm(B_power, B)  \n",
    "        diag_sum = torch.diagonal(B_power, dim1=-2, dim2=-1).sum(dim=-1)  \n",
    "        cycle_penalty += diag_sum / k \n",
    "\n",
    "    return cycle_penalty.mean()\n",
    "\n",
    "def connectivity_loss(B):\n",
    "    \n",
    "    \"\"\" \n",
    "    Encourages the graph to contain a single connected path structure, \n",
    "    verified via Laplacian eigenvalues and connected component analysis.\n",
    "    \n",
    "    Args:\n",
    "        B (torch.Tensor): Adjacency matrix of shape (batch_size, N, N).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Path structure loss value.\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size, num_nodes, _ = B.shape\n",
    "    deg_out = B.sum(dim=-1)  \n",
    "    D = torch.diag_embed(deg_out)\n",
    "    L = D - B\n",
    "    eigvals = torch.linalg.eigvals(L).real  \n",
    "    zero_threshold = 1e-5  \n",
    "    num_components = (eigvals.abs() < zero_threshold).sum(dim=-1)\n",
    "    path_length = (B.sum(dim=(-1, -2)) / 2).long() + 1 \n",
    "    expected_components = num_nodes - path_length + 1\n",
    "    component_penalty = (num_components - expected_components) ** 2 / expected_components**2\n",
    "    max_pl = path_length.max().item()\n",
    "    max_pl = min(max_pl, num_nodes) \n",
    "    batch_path_eigvals = torch.zeros((batch_size, max_pl), device=B.device) \n",
    "\n",
    "    for idx, pl in enumerate(path_length):\n",
    "        pl_val = min(int(pl.item()), num_nodes)  \n",
    "\n",
    "        eigvals_path = 2 - 2 * torch.cos(torch.arange(pl_val, device=B.device) * torch.pi / pl_val)\n",
    "        if pl_val > max_pl:\n",
    "            print(f\"Warning: pl_val ({pl_val}) exceeds max_pl ({max_pl}), skipping assignment\")\n",
    "            continue  \n",
    "\n",
    "        batch_path_eigvals[idx, :pl_val] = eigvals_path\n",
    "\n",
    "    sorted_eigvals = torch.sort(eigvals, dim=-1).values[:, :max_pl] \n",
    "    batch_path_eigvals = batch_path_eigvals[:, :max_pl]\n",
    "    spectral_penalty = ((sorted_eigvals - batch_path_eigvals) ** 2).mean(dim=-1) \n",
    "    \n",
    "    return (component_penalty + spectral_penalty).mean()\n",
    "\n",
    "def masked_bce_loss(pred, target):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes a masked Binary Cross-Entropy (BCE) loss with class imbalance handling.\n",
    "    \n",
    "    This function applies BCE loss only to a subset of the target values:  \n",
    "    - All positive (1) values are included.  \n",
    "    - A small fraction of negative (0) values are randomly sampled to reduce class imbalance.  \n",
    "    - A positive weight is applied to further adjust for the imbalance.  \n",
    "    \n",
    "    Args:\n",
    "        pred (torch.Tensor): Predicted logits of shape (B, N, N).\n",
    "        target (torch.Tensor): Ground truth labels of shape (B, N, N).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The mean masked BCE loss value.\n",
    "    \"\"\"\n",
    "\n",
    "    mask = ((target != 0) | (torch.rand_like(target) < 0.001)).float()\n",
    "    target_w = target.clone()\n",
    "    target_w[target == 1] = (1/2.6615810451242892e-03)\n",
    "    target_w[target == 0] = 0.00001\n",
    "    target_w = target_w.to(device)\n",
    "    loss = F.binary_cross_entropy(pred, target, reduction='none', weight=target_w*mask)\n",
    "    loss = loss * mask \n",
    "    return loss.sum() / mask.sum() \n",
    "\n",
    "def pinn_loss(output, Y_matrix, alpha, beta, zeta):\n",
    "    \n",
    "    \"\"\" \n",
    "    Computes the total loss including masked-BCE loss and physics-inspired penalties. \n",
    "    \"\"\"\n",
    "\n",
    "    Y_matrix = Y_matrix.float()\n",
    "    data_loss = masked_bce_loss(output, Y_matrix)    \n",
    "    L_deg = degree_loss(output)\n",
    "    L_cyc = cycle_loss(output)  \n",
    "    L_con = connectivity_loss(output)      \n",
    "    pinn_loss = alpha * L_deg + zeta*L_cyc + beta*L_con\n",
    "\n",
    "    total_loss = data_loss + 0*pinn_loss # Psi = 0\n",
    "    return total_loss\n",
    "    \n",
    "def evaluate_model(model, test_dataloader, device):\n",
    "    \n",
    "    \"\"\"\n",
    "    Evaluate the architecture using ROC-AUC Metric\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()  \n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():  \n",
    "        for adj_tensor, x_matrix, y_matrix in test_dataloader:\n",
    "            adj_tensor, x_matrix, y_matrix = adj_tensor.to(device), x_matrix.to(device), y_matrix.to(device)\n",
    "            output = model(x_matrix, adj_tensor)  \n",
    "            all_outputs.append(output.cpu().numpy().flatten())\n",
    "            all_targets.append(y_matrix.cpu().numpy().flatten())\n",
    "\n",
    "    all_outputs = np.concatenate(all_outputs).astype(int)\n",
    "    all_targets = np.concatenate(all_targets).astype(int)\n",
    "    \n",
    "    predictions = (all_outputs > 0.5).astype(int)\n",
    "    auc_roc = roc_auc_score(all_targets, all_outputs)\n",
    "    return auc_roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1e8489-5eb4-47c8-bb1d-904b019c3e62",
   "metadata": {},
   "source": [
    "## 3. Train path predictor without physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bddb0e3c-11f4-412a-bc4f-db8f13380065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Epoch 1, \tTrain Loss: 5.14408466\n",
      "[i] Epoch 2, \tTrain Loss: 4.37899471\n",
      "[i] Epoch 3, \tTrain Loss: 4.20036497\n",
      "[i] Epoch 4, \tTrain Loss: 4.15533141\n",
      "[i] Epoch 5, \tTrain Loss: 4.02720269\n",
      "[i] Epoch 6, \tTrain Loss: 4.01665365\n",
      "[i] Epoch 7, \tTrain Loss: 4.01995330\n",
      "[i] Epoch 8, \tTrain Loss: 4.05554997\n",
      "[i] Epoch 9, \tTrain Loss: 4.04662886\n",
      "[i] Epoch 10, \tTrain Loss: 4.03627675\n",
      "[i] ROC-AUC: \t0.82979\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Defines model hyperparameters such as input/output dimensions, hidden layer size,\n",
    "and dropout rate.\n",
    "\"\"\"\n",
    "\n",
    "in_features = dataset[0][1].shape[1]      \n",
    "out_features = dataset[0][2].shape[1]    \n",
    "hidden_size = 512\n",
    "dropout = 0.1\n",
    "\n",
    "\"\"\"\n",
    "Sets the weights for the physics-inspired loss functions.\n",
    "These control the influence of different physics constraints on training.\n",
    "\"\"\"\n",
    "\n",
    "alpha, beta, zeta = 0.1,0.1,0.1\n",
    "\n",
    "\"\"\"\n",
    "Creates an instance of the GraphSAGE model with a DNN and moves it to the specified device (CPU/GPU).\n",
    "\"\"\"\n",
    "\n",
    "model = GraphSAGEWithDNN(in_features, hidden_size, out_features, dropout)\n",
    "model = model.to(device)\n",
    "\n",
    "\"\"\"\n",
    "Sets up the Adam optimizer with a learning rate of 0.01.\n",
    "Uses an exponential learning rate scheduler to decay the learning rate over epochs.\n",
    "\"\"\"\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) \n",
    "scheduler = ExponentialLR(optimizer, gamma=0.97)\n",
    "\n",
    "\"\"\"\n",
    "Trains the model for a specified number of epochs.\n",
    "Iterates through the dataset in batches, computes loss, performs backpropagation,\n",
    "and updates model weights using the optimizer.\n",
    "Handles potential linear algebra errors during loss computation.\n",
    "Tracks and prints average training loss per epoch.\n",
    "\"\"\"\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    total_loss = 0\n",
    "\n",
    "    for adj_tensor, X_matrix, Y_matrix in train_dataloader:\n",
    "       \n",
    "        adj_tensor = adj_tensor.to(device)\n",
    "        X_matrix = X_matrix.to(device)\n",
    "        Y_matrix = Y_matrix.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_matrix, adj_tensor)  \n",
    "        loss = pinn_loss(output, Y_matrix.float(), alpha, beta, zeta)  \n",
    "        \n",
    "        try:\n",
    "            loss.backward()\n",
    "        except torch.linalg.LinAlgError as e:\n",
    "            print(f\"LinAlgError: {e}\")\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    scheduler.step()\n",
    "    print(f\"[i] Epoch {epoch+1}, \\tTrain Loss: {avg_train_loss:.8f}\")\n",
    "\n",
    "\"\"\" \n",
    "Optional: Save model weights for future use.\n",
    "- Transformer weights (adjacency encoder) are saved separately from the DNN weights.\n",
    "\"\"\"\n",
    "\n",
    "torch.save(model.graphsage.state_dict(), \"Weights/no_pinn_graphsage_weights.pth\")  \n",
    "torch.save(model.dnn.state_dict(), \"Weights/no_pinn_pinn_dnn_weights.pth\")\n",
    "\n",
    "\"\"\"\n",
    "Evaluate the architecture using ROC-AUC Metric\n",
    "\"\"\"\n",
    "\n",
    "auc_roc = evaluate_model(model, test_dataloader, device)\n",
    "print(f\"[i] ROC-AUC: \\t{auc_roc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b3371c-5492-4faa-bca9-585cc469c061",
   "metadata": {},
   "source": [
    "## 4. Train path predictor with physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d59e7167-1984-4264-bb52-3ff937c167a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Epoch 1, \tTrain Loss: 372.89824911\n",
      "[i] Epoch 2, \tTrain Loss: 368.66578381\n",
      "[i] Epoch 3, \tTrain Loss: 367.44918999\n",
      "[i] Epoch 4, \tTrain Loss: 367.17449130\n",
      "[i] Epoch 5, \tTrain Loss: 366.50590633\n",
      "[i] Epoch 6, \tTrain Loss: 366.07718776\n",
      "[i] Epoch 7, \tTrain Loss: 365.80567815\n",
      "[i] Epoch 8, \tTrain Loss: 365.78322308\n",
      "[i] Epoch 9, \tTrain Loss: 365.58628200\n",
      "[i] Epoch 10, \tTrain Loss: 365.52144623\n",
      "[i] Epoch 11, \tTrain Loss: 365.53299948\n",
      "[i] Epoch 12, \tTrain Loss: 365.02650158\n",
      "[i] Epoch 13, \tTrain Loss: 365.54958109\n",
      "[i] Epoch 14, \tTrain Loss: 364.73675772\n",
      "[i] Epoch 15, \tTrain Loss: 364.56448247\n",
      "[i] Epoch 16, \tTrain Loss: 364.57081252\n",
      "[i] Epoch 17, \tTrain Loss: 365.59575301\n",
      "[i] Epoch 18, \tTrain Loss: 365.14550546\n",
      "[i] Epoch 19, \tTrain Loss: 367.72257526\n",
      "[i] Epoch 20, \tTrain Loss: 372.68691078\n",
      "[i] ROC-AUC: \t0.84181\n"
     ]
    }
   ],
   "source": [
    "def pinn_loss(output, Y_matrix, alpha, beta, zeta):\n",
    "    \n",
    "    \"\"\" \n",
    "    Computes the total loss including masked-BCE loss and physics-inspired penalties. \n",
    "    \"\"\"\n",
    "\n",
    "    Y_matrix = Y_matrix.float()\n",
    "    data_loss = masked_bce_loss(output, Y_matrix)    \n",
    "    L_deg = corrected_degree_loss(output)\n",
    "    L_cyc = scaled_corrected_cycle_loss(output)  \n",
    "    L_con = path_structure_loss(output)      \n",
    "    pinn_loss = alpha * L_deg + zeta*L_cyc + beta*L_con\n",
    "\n",
    "    total_loss = data_loss + pinn_loss # Psi = 1\n",
    "    return total_loss\n",
    "    \n",
    "\"\"\"\n",
    "Defines model hyperparameters such as input/output dimensions, hidden layer size,\n",
    "and dropout rate.\n",
    "\"\"\"\n",
    "\n",
    "in_features = dataset[0][1].shape[1]      \n",
    "out_features = dataset[0][2].shape[1]    \n",
    "hidden_size = 512\n",
    "dropout = 0.1\n",
    "\n",
    "\"\"\"\n",
    "Log training loss\n",
    "\"\"\"\n",
    "\n",
    "csv_filename = \"Exports/warmup_training_log.csv\"\n",
    "with open(csv_filename, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Epoch\", \"Batch\", \"Loss\"])  \n",
    "\n",
    "\"\"\"\n",
    "Sets the weights for the physics-inspired loss functions.\n",
    "These control the influence of different physics constraints on training.\n",
    "\"\"\"\n",
    "\n",
    "alpha, beta, zeta = 1,0.0001,1 \n",
    "\n",
    "\"\"\"\n",
    "Creates an instance of the GraphSAGE model with a DNN and moves it to the specified device (CPU/GPU).\n",
    "\"\"\"\n",
    "\n",
    "model = GraphSAGEWithDNN(in_features, hidden_size, out_features, dropout)\n",
    "model = model.to(device)\n",
    "\n",
    "\"\"\"\n",
    "Sets up the Adam optimizer with a learning rate of 0.01.\n",
    "Uses an exponential learning rate scheduler to decay the learning rate over epochs.\n",
    "\"\"\"\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) \n",
    "scheduler = ExponentialLR(optimizer, gamma=0.97)\n",
    "\n",
    "\"\"\"\n",
    "Trains the model for a specified number of epochs.\n",
    "Iterates through the dataset in batches, computes loss, performs backpropagation,\n",
    "and updates model weights using the optimizer.\n",
    "Handles potential linear algebra errors during loss computation.\n",
    "Tracks and prints average training loss per epoch.\n",
    "\"\"\"\n",
    "\n",
    "num_epochs = 20\n",
    "train_losses = []\n",
    "log_data = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (adj_tensor, X_matrix, Y_matrix) in enumerate(train_dataloader):\n",
    "       \n",
    "        adj_tensor = adj_tensor.to(device)\n",
    "        X_matrix = X_matrix.to(device)\n",
    "        Y_matrix = Y_matrix.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_matrix, adj_tensor)  \n",
    "        loss = pinn_loss(output, Y_matrix.float(), alpha, beta, zeta)  \n",
    "        \n",
    "        try:\n",
    "            loss.backward()\n",
    "        except torch.linalg.LinAlgError as e:\n",
    "            print(f\"LinAlgError: {e}\")\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    scheduler.step()\n",
    "    log_data.append([epoch + 1, batch_idx + 1, loss.item()])\n",
    "    print(f\"[i] Epoch {epoch+1}, \\tTrain Loss: {avg_train_loss:.8f}\")\n",
    "\n",
    "\"\"\"\n",
    "Save logs\n",
    "\"\"\"\n",
    "with open(csv_filename, mode=\"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(log_data)\n",
    "\n",
    "\"\"\" \n",
    "Optional: Save model weights for future use.\n",
    "- Transformer weights (adjacency encoder) are saved separately from the DNN weights.\n",
    "\"\"\"\n",
    "\n",
    "#torch.save(model.graphsage.state_dict(), \"Weights/085-pinn_graphsage_weights.pth\")  \n",
    "#torch.save(model.dnn.state_dict(), \"Weights/085-pinn_dnn_weights.pth\")\n",
    "\n",
    "\"\"\"\n",
    "Evaluate the architecture using ROC-AUC Metric\n",
    "\"\"\"\n",
    "\n",
    "auc_roc = evaluate_model(model, test_dataloader, device)\n",
    "print(f\"[i] ROC-AUC: \\t{auc_roc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f732f1-1fa1-4ba0-ae40-e92f716951e9",
   "metadata": {},
   "source": [
    "## 5. Evaluate both models and plot ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dac25d3-0001-4893-a92f-d5ee8aa09443",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nopinn = GraphSAGEWithDNN(in_features, hidden_size, out_features, dropout)\n",
    "model_nopinn.graphsage.load_state_dict(torch.load(\"Weights/no_pinn_graphsage_weights.pth\"))\n",
    "model_nopinn.dnn.load_state_dict(torch.load(\"Weights/no_pinn_pinn_dnn_weights.pth\"))\n",
    "model_nopinn.to(device)\n",
    "model_nopinn.eval()\n",
    "\n",
    "model = GraphSAGEWithDNN(in_features, hidden_size, out_features, dropout)\n",
    "model.graphsage.load_state_dict(torch.load(\"Weights/086-pinn_graphsage_weights.pth\"))\n",
    "model.dnn.load_state_dict(torch.load(\"Weights/086-pinn_dnn_weights.pth\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def compute_roc_auc(model, dataloader, device):\n",
    "    \"\"\" Compute ROC-AUC values (FPR, TPR, AUC score) for a given model. \"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for adj_tensor, X_matrix, Y_matrix in dataloader:\n",
    "            adj_tensor = adj_tensor.to(device)\n",
    "            X_matrix = X_matrix.to(device)\n",
    "            Y_matrix = Y_matrix.to(device)\n",
    "\n",
    "            outputs = model(X_matrix, adj_tensor)  \n",
    "            probabilities = torch.sigmoid(outputs)  \n",
    "\n",
    "            all_probs.append(probabilities.cpu().numpy().flatten())  \n",
    "            all_labels.append(Y_matrix.cpu().numpy().flatten())  \n",
    "\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "\n",
    "def plot_roc_auc_comparison(model1, model2, dataloader, device, label1=\"Model\", label2=\"Model No PINN\"):\n",
    "    \"\"\" Plot ROC-AUC curves for two models on the same graph. \"\"\"\n",
    "    \n",
    "    fpr1, tpr1, auc1 = compute_roc_auc(model1, dataloader, device)\n",
    "    fpr2, tpr2, auc2 = compute_roc_auc(model2, dataloader, device)\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.plot(fpr1, tpr1, color='blue', lw=1, label=f\"{label1} (AUC = {auc1:.4f})\")\n",
    "    plt.plot(fpr2, tpr2, color='red', lw=1, label=f\"{label2} (AUC = {auc2:.4f})\")\n",
    "    plt.plot([0, 1], [0, 1], color='black', linestyle=\"dotted\", lw=1, label=\"Baseline\")  \n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\",  fontsize=10)\n",
    "    plt.ylabel(\"True Positive Rate\",  fontsize=10)\n",
    "    plt.title(\"ROC Curve Comparison\",  fontsize=12)\n",
    "    plt.legend(loc='lower right', fontsize=10, frameon=True, framealpha=1)\n",
    "    plt.grid(color='black', linestyle='-', linewidth=.5, alpha=.3)\n",
    "    plt.draw()\n",
    "    plt.box(False)    \n",
    "    plt.savefig('Exports/model_roc_auc_compare.jpeg', dpi=400, bbox_inches='tight', transparent=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_auc_comparison(model, model_nopinn, test_dataloader, device, label1=r'$\\Psi = 1$'+f\"\\t\", label2=r'$\\Psi = 0$'+f\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b2c756-af59-4832-9fd2-89c1c56aa31b",
   "metadata": {},
   "source": [
    "## 7. Encoder Architecture for start/end node prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a238c8fe-21be-4888-83dd-f104cb148b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(torch.nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Autoencoder (AE) model\n",
    "    \n",
    "    Args:\n",
    "        hidden_size (int): Number of hidden features in the GraphSAGE output.\n",
    "        out_features (int): Number of features in the input X_matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size: int, out_features: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size, 128),                  # Added (_,128) layer\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 36),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(36, 18),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(18, 9)  \n",
    "        )\n",
    "        \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(9, 18),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(18, 36),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(36, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, out_features)                  # Added (_,128) layer\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \"\"\"\n",
    "        Forward pass for the autoencoder.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch_size, num_nodes, hidden_size).  \n",
    "        Returns:\n",
    "            Tensor: Reconstructed output of shape (batch_size, num_nodes, out_features).\n",
    "        \"\"\"\n",
    "        \n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "class GraphSAGEWithAE(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    GraphSAGE model combined with an Autoencoder (AE) for feature learning.\n",
    "    \n",
    "    Args:\n",
    "        in_features (int): Number of input node features.\n",
    "        hidden_size (int): Number of hidden units in GraphSAGE.\n",
    "        out_features (int): Output feature size (same as X_matrix.shape[2]).\n",
    "        dropout (float, optional): Dropout rate. Defaults to 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, hidden_size, out_features, dropout=0):\n",
    "        super().__init__()\n",
    "        self.graphsage = GraphSAGEModel(in_features, hidden_size, hidden_size, dropout)\n",
    "        self.autoencoder = AE(hidden_size, out_features)\n",
    "\n",
    "    def forward(self, x, adj_tensor):\n",
    "    \n",
    "        \"\"\"\n",
    "        Forward pass through GraphSAGE followed by the autoencoder.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input feature matrix of shape (batch_size, num_nodes, in_features).\n",
    "            adj_tensor (Tensor): Adjacency matrix of shape (batch_size, num_nodes, num_nodes).\n",
    "        Returns:\n",
    "            Tensor: Reconstructed feature matrix of shape (batch_size, num_nodes, out_features).\n",
    "        \"\"\"\n",
    "        \n",
    "        node_embeddings = self.graphsage(x, adj_tensor)\n",
    "        reconstruction = self.autoencoder(node_embeddings)\n",
    "        return reconstruction\n",
    "\n",
    "class EncoderWithClassifier(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Encoder model with a classifier for binary node classification.\n",
    "    \n",
    "    Args:\n",
    "        graphsage (nn.Module): Pretrained GraphSAGE model.\n",
    "        pretrained_encoder (nn.Module): Pretrained encoder (Autoencoder's encoder part).\n",
    "        latent_dim (int): Size of the latent representation.\n",
    "        freeze (bool): If True, freezes GraphSAGE and encoder layers during training.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, graphsage: nn.Module, pretrained_encoder: nn.Module, latent_dim: int, freeze: bool):\n",
    "        super().__init__()\n",
    "        self.graphsage = graphsage \n",
    "        self.encoder = pretrained_encoder\n",
    "\n",
    "        if freeze:\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.graphsage.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim, latent_dim),      \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(latent_dim, 1),   \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, adj_tensor):\n",
    "        \n",
    "        \"\"\"\n",
    "        Forward pass through GraphSAGE, encoder, and classifier.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input feature matrix of shape (batch_size, num_nodes, in_features).\n",
    "            adj_tensor (Tensor): Adjacency matrix of shape (batch_size, num_nodes, num_nodes).\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: Classification probabilities of shape (batch_size, num_nodes).\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size, num_nodes, _ = x.shape  \n",
    "        node_embeddings = self.graphsage(x, adj_tensor)\n",
    "        node_embeddings = node_embeddings.view(batch_size * num_nodes, node_embeddings.shape[2])\n",
    "        latent_repr = self.encoder(node_embeddings)\n",
    "        classification_output = self.classifier(latent_repr)\n",
    "        classification_output = classification_output.view(batch_size, num_nodes)\n",
    "        return classification_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c719c5f-06c7-41e7-9bf3-9abb7a48f4b5",
   "metadata": {},
   "source": [
    "## 8. Train encoder using self-supervised encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4cbb15e-4f98-43ef-848f-61d6101c1dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.03863320\n",
      "Epoch 2, Train Loss: 0.01139502\n",
      "Epoch 3, Train Loss: 0.00975788\n",
      "Epoch 4, Train Loss: 0.00734679\n",
      "Epoch 5, Train Loss: 0.00401579\n",
      "Epoch 6, Train Loss: 0.00293719\n",
      "Epoch 7, Train Loss: 0.00708617\n",
      "Epoch 8, Train Loss: 0.00161704\n",
      "Epoch 9, Train Loss: 0.00110221\n",
      "Epoch 10, Train Loss: 0.00071511\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hyperparameter Initialization\n",
    "\n",
    "Defines the key hyperparameters for the model, including:\n",
    "- in_features: The number of input node features, extracted from the dataset.\n",
    "- hidden_size: The size of the hidden layers in the model.\n",
    "- dropout: Dropout rate to prevent overfitting.\n",
    "\"\"\"\n",
    "\n",
    "in_features = dataset[0][1].shape[1]  \n",
    "hidden_size = 512\n",
    "dropout = 0.01\n",
    "\n",
    "\"\"\"\n",
    "Model Initialization\n",
    "\n",
    "- Initializes the GraphSAGEWithAE model using the defined hyperparameters.\n",
    "- Moves the model to the appropriate computing device (CPU/GPU).\n",
    "\"\"\"\n",
    "\n",
    "model = GraphSAGEWithAE(in_features, hidden_size, in_features, dropout)\n",
    "model = model.to(device)\n",
    "\n",
    "\"\"\"\n",
    "Optimizer and Loss Function\n",
    "\n",
    "- Uses the Adam optimizer with a learning rate of 0.001 to train the model.\n",
    "- Mean Squared Error (MSE) is used as the loss function to measure reconstruction quality.\n",
    "\"\"\"\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "\"\"\"\n",
    "Autoencoder Training Loop\n",
    "\n",
    "- Trains the autoencoder for a specified number of epochs.\n",
    "- Iterates over the training dataset, performs forward and backward passes, and updates model weights.\n",
    "- Computes the reconstruction loss based on the difference between the original and reconstructed node features.\n",
    "- Outputs the training loss for each epoch.\n",
    "\"\"\"\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for adj_tensor, X_matrix, _ in train_dataloader: \n",
    "        adj_tensor = adj_tensor.to(device)\n",
    "        X_matrix = X_matrix.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        reconstruction = model(X_matrix, adj_tensor)  \n",
    "\n",
    "        loss = criterion(reconstruction, X_matrix)  \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {total_loss/len(train_dataloader):.8f}\")\n",
    "\n",
    "\"\"\"\n",
    "Model Weights Saving\n",
    "\n",
    "- Saves the trained weights of the GraphSAGE and Autoencoder components.\n",
    "- Weights are stored in the 'Weights' directory for later use in downstream tasks.\n",
    "\"\"\"\n",
    "\n",
    "torch.save(model.graphsage.state_dict(), \"Weights/graphsage_weights.pth\")  \n",
    "torch.save(model.autoencoder.state_dict(), \"Weights/autoencoder_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52b7ab-09f5-40c1-b1a9-ae1f1291d0ea",
   "metadata": {},
   "source": [
    "## 9. Fine tune SAGEConv+Encoder+Classifier for start node prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fa85272-44b7-4419-a25e-5822ba6cee98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Classifier Train Loss: 0.51988231\n",
      "Epoch 2, Classifier Train Loss: 0.07938496\n",
      "Epoch 3, Classifier Train Loss: 0.02257822\n",
      "Epoch 4, Classifier Train Loss: 0.01578102\n",
      "Epoch 5, Classifier Train Loss: 0.01362000\n",
      "Epoch 6, Classifier Train Loss: 0.01253690\n",
      "Epoch 7, Classifier Train Loss: 0.01197894\n",
      "Epoch 8, Classifier Train Loss: 0.01153727\n",
      "Epoch 9, Classifier Train Loss: 0.01129567\n",
      "Epoch 10, Classifier Train Loss: 0.01112559\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load Pretrained GraphSAGE + Encoder and Initialize Classifier\n",
    "\n",
    "- Loads the pretrained GraphSAGE model from saved weights.\n",
    "- Loads the pretrained autoencoder and extracts the encoder component.\n",
    "- Initializes the classifier model with the pretrained encoder.\n",
    "- Allows optional fine-tuning of the GraphSAGE and encoder by setting `freeze` to False.\n",
    "\"\"\"\n",
    "\n",
    "graphsage_model = GraphSAGEModel(in_features, hidden_size, hidden_size, dropout).to(device)\n",
    "graphsage_model.load_state_dict(torch.load(\"Weights/graphsage_weights.pth\"))  \n",
    "\n",
    "pretrained_ae = AE(hidden_size, in_features).to(device)  \n",
    "pretrained_ae.load_state_dict(torch.load(\"Weights/autoencoder_weights.pth\"))  \n",
    "pretrained_encoder = pretrained_ae.encoder \n",
    "\n",
    "latent_dim = 9           \n",
    "freeze = False  \n",
    "classifier_model = EncoderWithClassifier(graphsage_model, pretrained_encoder, latent_dim, freeze).to(device)\n",
    "\n",
    "\"\"\"\n",
    "Define Optimizer, Scheduler, and Loss Function\n",
    "\n",
    "- Uses Adam optimizer with an initial learning rate of 0.01.\n",
    "- Applies an exponential learning rate decay with a gamma value of 0.9.\n",
    "- Binary Cross-Entropy Loss (BCELoss) is used for classification.\n",
    "\"\"\"\n",
    "\n",
    "optimizer = torch.optim.Adam(classifier_model.parameters(), lr=0.0001)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "\n",
    "\"\"\"\n",
    "Training Loop for Graph Embeddings -> Encoder -> Classifier\n",
    "\n",
    "- Iterates over the training dataset for a specified number of epochs.\n",
    "- Extracts graph adjacency tensors and node feature matrices.\n",
    "- Retrieves start node labels from the last feature in X_matrix.\n",
    "- Performs forward propagation, computes loss, and updates model parameters.\n",
    "- Applies a learning rate scheduler for gradual decay.\n",
    "\"\"\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    classifier_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for adj_tensor, X_matrix, _ in train_dataloader:  \n",
    "        adj_tensor = adj_tensor.to(device)\n",
    "        \n",
    "        labels = X_matrix[:, :, -1].float()  \n",
    "        labels = labels.to(device)         \n",
    "        \n",
    "        X_matrix_mask = X_matrix.clone()  \n",
    "        X_matrix_mask[:, :, -1] = 0 \n",
    "        X_matrix_mask = X_matrix_mask.to(device)  \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        classification_output = classifier_model(X_matrix_mask, adj_tensor)  \n",
    "        loss = criterion(classification_output, labels)  \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Classifier Train Loss: {total_loss / len(train_dataloader):.8f}\")\n",
    "\n",
    "\"\"\"\n",
    "Save weights\n",
    "\"\"\"\n",
    "torch.save(classifier_model.graphsage.state_dict(), \"Weights/sn_graphsage_ae_classifier_weights.pth\")\n",
    "torch.save(classifier_model.encoder.state_dict(), \"Weights/sn_encoder_ae_classifier_weights.pth\")\n",
    "torch.save(classifier_model.classifier.state_dict(), \"Weights/sn_classifier_ae_classifier_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6400d364-20c8-4159-bdf3-b1fd48a62890",
   "metadata": {},
   "source": [
    "## 10. Find optimal threshold for reconstruction error indicating start node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e74f34f-4b06-4137-8d92-266512085773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold  : 0.00220\n",
      "Test ROC AUC       : 0.9571\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Find the optimal threshold for classification.\n",
    "\n",
    "- Evaluate the classifier on the training set without updating weights.\n",
    "- Store true labels and model predictions.\n",
    "- Iterate over a range of thresholds to find the one with the highest score.\n",
    "- Compute final evaluation metrics using the best threshold.\n",
    "\"\"\"\n",
    "\n",
    "classifier_model.eval()  \n",
    "all_labels = []\n",
    "all_outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for adj_tensor, X_matrix, _ in test_dataloader:\n",
    "        adj_tensor = adj_tensor.to(device)\n",
    "        X_matrix = X_matrix.to(device)\n",
    "\n",
    "        labels = X_matrix[:, :, -1].float() \n",
    "        classification_output = classifier_model(X_matrix, adj_tensor)  \n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy().flatten())  \n",
    "        all_outputs.extend(classification_output.cpu().numpy().flatten())  \n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_outputs = np.array(all_outputs)\n",
    "\n",
    "best_threshold = 0\n",
    "best_s = 0\n",
    "thresholds = np.arange(0, 0.9, 0.0001)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    preds = (all_outputs > threshold).astype(float)  \n",
    "    s = roc_auc_score(all_labels, preds) \n",
    "\n",
    "    if s > best_s:  \n",
    "        best_s = s\n",
    "        best_threshold = threshold\n",
    "\n",
    "\"\"\"\n",
    "Evaluate the architecture using ROC-AUC Metric\n",
    "\"\"\"\n",
    "\n",
    "final_preds = (all_outputs > best_threshold).astype(float)  \n",
    "roc_auc = roc_auc_score(all_labels, final_preds)\n",
    "\n",
    "print(f\"Optimal Threshold  : {best_threshold:.5f}\")\n",
    "print(f\"Test ROC AUC       : {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4130809a-68d7-44e8-9aab-0ed7f43aaf5a",
   "metadata": {},
   "source": [
    "## 11. Fine tune SAGEConv+Encoder+Classifier for end node prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0dff066c-f7c2-4940-9bba-43c6338439a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Classifier Train Loss: 0.14209690\n",
      "Epoch 2, Classifier Train Loss: 0.05622134\n",
      "Epoch 3, Classifier Train Loss: 0.05223998\n",
      "Epoch 4, Classifier Train Loss: 0.05210115\n",
      "Epoch 5, Classifier Train Loss: 0.05192966\n",
      "Epoch 6, Classifier Train Loss: 0.05175074\n",
      "Epoch 7, Classifier Train Loss: 0.05223931\n",
      "Epoch 8, Classifier Train Loss: 0.05189640\n",
      "Epoch 9, Classifier Train Loss: 0.05188802\n",
      "Epoch 10, Classifier Train Loss: 0.05164744\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load Pretrained GraphSAGE + Encoder and Initialize Classifier\n",
    "\n",
    "- Loads the pretrained GraphSAGE model from saved weights.\n",
    "- Loads the pretrained autoencoder and extracts the encoder component.\n",
    "- Initializes the classifier model with the pretrained encoder.\n",
    "- Allows optional fine-tuning of the GraphSAGE and encoder by setting `freeze` to False.\n",
    "\"\"\"\n",
    "\n",
    "graphsage_model = GraphSAGEModel(in_features, hidden_size, hidden_size, dropout).to(device)\n",
    "graphsage_model.load_state_dict(torch.load(\"Weights/graphsage_weights.pth\"))  \n",
    "\n",
    "pretrained_ae = AE(hidden_size, in_features).to(device)  \n",
    "pretrained_ae.load_state_dict(torch.load(\"Weights/autoencoder_weights.pth\"))  \n",
    "pretrained_encoder = pretrained_ae.encoder  \n",
    "\n",
    "latent_dim = 9           \n",
    "freeze = False   \n",
    "classifier_model = EncoderWithClassifier(graphsage_model, pretrained_encoder, latent_dim, freeze).to(device)\n",
    "\n",
    "\"\"\"\n",
    "Define Optimizer, Scheduler, and Loss Function\n",
    "\n",
    "- Uses Adam optimizer with an initial learning rate of 0.001.\n",
    "- Applies an exponential learning rate decay with a gamma value of 0.9.\n",
    "- Binary Cross-Entropy Loss (BCELoss) is used for classification.\n",
    "\"\"\"\n",
    "\n",
    "optimizer = torch.optim.Adam(classifier_model.parameters(), lr=0.001)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "\n",
    "\"\"\"\n",
    "Training Loop for Graph Embeddings -> Encoder -> Classifier\n",
    "\n",
    "- Iterates over the training dataset for a specified number of epochs.\n",
    "- Extracts graph adjacency tensors and node feature matrices.\n",
    "- Retrieves end node labels from the second-to-last feature in X_matrix.\n",
    "- Performs forward propagation, computes loss, and updates model parameters.\n",
    "- Applies a learning rate scheduler for gradual decay.\n",
    "\"\"\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    classifier_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for adj_tensor, X_matrix, _ in train_dataloader:  \n",
    "        adj_tensor = adj_tensor.to(device)\n",
    "        \n",
    "        labels = X_matrix[:, :, -2].float()  \n",
    "        labels = labels.to(device)         \n",
    "        \n",
    "        X_matrix_mask = X_matrix.clone()  \n",
    "        X_matrix_mask[:, :, -2] = 0 \n",
    "        X_matrix_mask = X_matrix_mask.to(device)  \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        classification_output = classifier_model(X_matrix_mask, adj_tensor)  \n",
    "        loss = criterion(classification_output, labels)  \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Classifier Train Loss: {total_loss / len(train_dataloader):.8f}\")\n",
    "\n",
    "\"\"\"\n",
    "Save Weights\n",
    "\"\"\"\n",
    "torch.save(classifier_model.graphsage.state_dict(), \"Weights/en_graphsage_ae_classifier_weights.pth\")\n",
    "torch.save(classifier_model.encoder.state_dict(), \"Weights/en_encoder_ae_classifier_weights.pth\")\n",
    "torch.save(classifier_model.classifier.state_dict(), \"Weights/en_classifier_ae_classifier_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517c4b71-53e1-4047-b71f-646cef31df85",
   "metadata": {},
   "source": [
    "## 12. Find optimal threshold for reconstruction error indicating end node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4220d2b-5400-4baf-b6cd-3be8d831d3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold  : 0.00020\n",
      "Test ROC AUC       : 0.9591\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Find the optimal threshold for classification.\n",
    "\n",
    "- Evaluate the classifier on the training set without updating weights.\n",
    "- Store true labels and model predictions.\n",
    "- Iterate over a range of thresholds to find the one with the highest score.\n",
    "- Compute final evaluation metrics using the best threshold.\n",
    "\"\"\"\n",
    "\n",
    "classifier_model.eval()  \n",
    "all_labels = []\n",
    "all_outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for adj_tensor, X_matrix, _ in test_dataloader:\n",
    "        adj_tensor = adj_tensor.to(device)\n",
    "        X_matrix = X_matrix.to(device)\n",
    "\n",
    "        labels = X_matrix[:, :, -2].float() \n",
    "        classification_output = classifier_model(X_matrix, adj_tensor)  \n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy().flatten())  \n",
    "        all_outputs.extend(classification_output.cpu().numpy().flatten())  \n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_outputs = np.array(all_outputs)\n",
    "\n",
    "best_threshold = 0\n",
    "best_s = 0\n",
    "thresholds = np.arange(0, 0.9, 0.0001)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    preds = (all_outputs > threshold).astype(float)  \n",
    "    s = roc_auc_score(all_labels, preds) \n",
    "\n",
    "    if s > best_s:  \n",
    "        best_s = s\n",
    "        best_threshold = threshold\n",
    "\n",
    "\"\"\"\n",
    "Evaluate the architecture using ROC-AUC Metric\n",
    "\"\"\"\n",
    "\n",
    "final_preds = (all_outputs > best_threshold).astype(float)  \n",
    "roc_auc = roc_auc_score(all_labels, final_preds)\n",
    "\n",
    "print(f\"Optimal Threshold  : {best_threshold:.5f}\")\n",
    "print(f\"Test ROC AUC       : {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e99bad8-6a26-483b-aff1-df17f9b4b626",
   "metadata": {},
   "source": [
    "## 13. Plot four ROC-AUC curves and confusion matrix from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dbd767-4ed9-48ca-ac60-662673123679",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Start by loading the four models : Path prediction with and without PINN loss, then the 2 classification blocks\n",
    "\"\"\"\n",
    "\n",
    "model = GraphSAGEWithDNN(in_features, hidden_size, out_features, dropout)\n",
    "model.graphsage.load_state_dict(torch.load(\"Weights/086-pinn_graphsage_weights.pth\"))\n",
    "model.dnn.load_state_dict(torch.load(\"Weights/086-pinn_dnn_weights.pth\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "model_nopinn = GraphSAGEWithDNN(in_features, hidden_size, out_features, dropout)\n",
    "model_nopinn.graphsage.load_state_dict(torch.load(\"Weights/no_pinn_graphsage_weights.pth\"))\n",
    "model_nopinn.dnn.load_state_dict(torch.load(\"Weights/no_pinn_pinn_dnn_weights.pth\"))\n",
    "model_nopinn.to(device)\n",
    "model_nopinn.eval()\n",
    "\n",
    "graphsage_model_1 = GraphSAGEModel(in_features, hidden_size, hidden_size, dropout)  \n",
    "pretrained_ae_1 = AE(hidden_size, in_features)\n",
    "pretrained_encoder_1 = pretrained_ae_1.encoder   \n",
    "\n",
    "ae_sn = EncoderWithClassifier(graphsage_model_1, pretrained_encoder_1, latent_dim=9, freeze = False)\n",
    "ae_sn.graphsage.load_state_dict(torch.load(\"Weights/sn_graphsage_ae_classifier_weights.pth\"))  \n",
    "ae_sn.encoder.load_state_dict(torch.load(\"Weights/sn_encoder_ae_classifier_weights.pth\"))\n",
    "ae_sn.classifier.load_state_dict(torch.load(\"Weights/sn_classifier_ae_classifier_weights.pth\"))\n",
    "ae_sn.to(device)\n",
    "ae_sn.eval()\n",
    "\n",
    "graphsage_model_2 = GraphSAGEModel(in_features, hidden_size, hidden_size, dropout) \n",
    "pretrained_ae_2 = AE(hidden_size, in_features)\n",
    "pretrained_encoder_2 = pretrained_ae_2.encoder   \n",
    "\n",
    "ae_en = EncoderWithClassifier(graphsage_model_2, pretrained_encoder_2, latent_dim=9, freeze = False)\n",
    "ae_en.graphsage.load_state_dict(torch.load(\"Weights/en_graphsage_ae_classifier_weights.pth\"))  \n",
    "ae_en.encoder.load_state_dict(torch.load(\"Weights/en_encoder_ae_classifier_weights.pth\"))\n",
    "ae_en.classifier.load_state_dict(torch.load(\"Weights/en_classifier_ae_classifier_weights.pth\"))\n",
    "ae_en.to(device)\n",
    "ae_en.eval()\n",
    "\n",
    "def compute_roc_auc(model, dataloader, device):\n",
    "    \n",
    "    \"\"\" \n",
    "    Compute ROC-AUC values (FPR, TPR, AUC score) for a given model. \n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for adj_tensor, X_matrix, Y_matrix in dataloader:\n",
    "            adj_tensor = adj_tensor.to(device)\n",
    "            X_matrix = X_matrix.to(device)\n",
    "            Y_matrix = Y_matrix.to(device)\n",
    "\n",
    "            outputs = model(X_matrix, adj_tensor)  \n",
    "            probabilities = torch.sigmoid(outputs)  \n",
    "\n",
    "            all_probs.append(probabilities.cpu().numpy().flatten())  \n",
    "            all_labels.append(Y_matrix.cpu().numpy().flatten())  \n",
    "\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "def compute_roc_auc_AE(model, dataloader, device, target, threshold): \n",
    "    \n",
    "    \"\"\" \n",
    "    Compute ROC-AUC values (FPR, TPR, AUC score) for a given model. \n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for adj_tensor, X_matrix, _ in dataloader:\n",
    "            adj_tensor = adj_tensor.to(device)\n",
    "            X_matrix = X_matrix.to(device)\n",
    "            labels = X_matrix[:, :, -target].float() \n",
    "            classification_output = model(X_matrix, adj_tensor)  \n",
    "            all_labels.extend(labels.cpu().numpy().flatten())  \n",
    "            all_probs.extend(classification_output.cpu().numpy().flatten())  \n",
    "    \n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "    preds = (all_probs > threshold).astype(float)\n",
    "    fpr, tpr, _ = roc_curve(all_labels, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "    \n",
    "    \n",
    "def plot_roc_auc_comparison(model1, \n",
    "                            model2, \n",
    "                            model3, \n",
    "                            model4, \n",
    "                            dataloader, \n",
    "                            device, \n",
    "                            label1, \n",
    "                            label2, \n",
    "                            label3,\n",
    "                            label4):\n",
    "\n",
    "    \n",
    "    \"\"\" \n",
    "    Plot ROC-AUC curves for two models on the same graph. \n",
    "    \"\"\"\n",
    "    \n",
    "    fpr1, tpr1, auc1 = compute_roc_auc(model1, dataloader, device)\n",
    "    fpr2, tpr2, auc2 = compute_roc_auc(model2, dataloader, device)\n",
    "    \n",
    "    fpr3, tpr3, auc3 = compute_roc_auc_AE(model3, dataloader, device, target=1, threshold=0.003)\n",
    "    fpr4, tpr4, auc4 = compute_roc_auc_AE(model4, dataloader, device,  target=2, threshold=0.00020)\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(fpr3, tpr3, color='red', lw=1, label=f\"{label3} (AUC = {auc3:.4f})\")\n",
    "    plt.plot(fpr4, tpr4, color='red', lw=1, linestyle='--', label=f\"{label4} (AUC = {auc4:.4f})\")\n",
    "    plt.plot(fpr1, tpr1, color='blue', lw=1, label=f\"{label1} (AUC = {auc1:.4f})\")\n",
    "    plt.plot(fpr2, tpr2, color='blue', linestyle=\"--\", lw=1, label=f\"{label2} (AUC = {auc2:.4f})\")\n",
    "    plt.plot([0, 1], [0, 1], color='black', linestyle=\"dotted\", lw=1, label=\"Baseline\")  # Random classifier line\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\",  fontsize=10)\n",
    "    plt.ylabel(\"True Positive Rate\",  fontsize=10)\n",
    "    plt.legend(loc='lower right', fontsize=10, frameon=True, framealpha=1)\n",
    "    plt.grid(color='black', linestyle='-', linewidth=.5, alpha=.3)\n",
    "    plt.draw()\n",
    "    plt.box(False)    \n",
    "    plt.savefig('Exports/ae_4model_roc_auc_compare.jpeg', dpi=400, bbox_inches='tight', transparent=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_auc_comparison(model, \n",
    "                        model_nopinn, \n",
    "                        ae_sn, \n",
    "                        ae_en, \n",
    "                        test_dataloader, \n",
    "                        device, \n",
    "                        label1=r'$\\mathcal{M}_1,\\quad\\Psi = 1$'+f\"\\t\", \n",
    "                        label2=r'$\\mathcal{M}_1,\\quad\\Psi = 0$'+f\"\\t\", \n",
    "                        label3=r'$\\mathcal{M}_2,\\quad\\Psi = 0$'+f\"\\t\", \n",
    "                        label4=r'$\\mathcal{M}_3,\\quad\\Psi = 0$'+f\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d733e4a1-53db-4bd0-9575-e330a783ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(model, dataloader, device, threshold=0.5, is_autoencoder=False, target=1):\n",
    "    \n",
    "    \"\"\" \n",
    "    Compute and print the confusion matrix for a given model. \n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for adj_tensor, X_matrix, Y_matrix in dataloader:\n",
    "            adj_tensor = adj_tensor.to(device)\n",
    "            X_matrix = X_matrix.to(device)\n",
    "\n",
    "            if is_autoencoder:\n",
    "                labels = X_matrix[:, :, -target]\n",
    "                classification_output = model(X_matrix, adj_tensor)\n",
    "                preds = (classification_output > threshold).float()\n",
    "            else:\n",
    "                Y_matrix = Y_matrix.to(device)\n",
    "                labels = Y_matrix\n",
    "                classification_output = model(X_matrix, adj_tensor)\n",
    "                preds = (classification_output> threshold).float() \n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy().flatten())\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    return cm\n",
    "\n",
    "def plot_confusion_matrix(cm, title=\"Confusion Matrix\", filename=None):\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.heatmap(cm_normalized, cbar=False, annot=True, fmt=\".2f\", cmap=\"Blues\", \n",
    "                xticklabels=[\"Negative\", \"Positive\"], \n",
    "                yticklabels=[\"Negative\", \"Positive\"], \n",
    "                vmin=0, vmax=1)  \n",
    "\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(title)\n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight', transparent=True)  \n",
    "    plt.show()\n",
    "\n",
    "cm1 = compute_confusion_matrix(model, test_dataloader, device, threshold=0.5)\n",
    "cm2 = compute_confusion_matrix(model_nopinn, test_dataloader, device, threshold=0.5)\n",
    "cm3 = compute_confusion_matrix(ae_sn, test_dataloader, device, threshold=0.003, is_autoencoder=True, target=1)\n",
    "cm4 = compute_confusion_matrix(ae_en, test_dataloader, device, threshold=0.00020, is_autoencoder=True, target=2)\n",
    "\n",
    "plot_confusion_matrix(cm1, title=r'$\\mathcal{M}_1,\\quad\\Psi=1$', filename='Exports/cm_m1_pinn.png')\n",
    "plot_confusion_matrix(cm2, title=r'$\\mathcal{M}_1,\\quad\\Psi=0$', filename='Exports/cm_m1_nopinn.png')\n",
    "plot_confusion_matrix(cm3, title=r'$\\mathcal{M}_2,\\quad\\Psi=0$', filename='Exports/cm_m3.png')\n",
    "plot_confusion_matrix(cm4, title=r'$\\mathcal{M}_3,\\quad\\Psi=0$', filename='Exports/cm_m4.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
